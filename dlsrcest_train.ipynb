{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9B6uOwN-0KD"
   },
   "source": [
    "# Single-Image SR-CEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3zCvhtt-0KF"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xS3qKCqc-0KG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ikDtqH-R-0KH"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = {}\n",
    "train_Y = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jy7Yw5rn-0KH"
   },
   "outputs": [],
   "source": [
    "def read_data(train_X, train_Y):\n",
    "\n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/train/low-res/8x/*/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        train_X[folder] = files\n",
    "    \n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/train/high-res/*/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        train_Y[folder] = files\n",
    "    \n",
    "    return train_X, train_Y\n",
    "\n",
    "train_X, train_Y = read_data(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dJDh146Z-0KI"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,data_dict,label_dict, transform=None):\n",
    "        df = data_dict\n",
    "        lf = label_dict\n",
    "        self.datas = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(\"Reading images to memory\")\n",
    "        \n",
    "        roots = df.keys()\n",
    "        for root in roots:\n",
    "            fnames = df[root]\n",
    "            for i in range(len(fnames)):\n",
    "                data = np.expand_dims((plt.imread(os.path.join(root,fnames[i]))), axis =2)\n",
    "                self.datas.append(data)\n",
    "\n",
    "        roots = lf.keys()\n",
    "        for root in roots:\n",
    "            fnames = lf[root]\n",
    "            for i in range(len(fnames)):\n",
    "                label = np.expand_dims((plt.imread(os.path.join(root,fnames[i]))), axis =2)\n",
    "                self.labels.append(label)\n",
    "        \n",
    "        if transform is None:\n",
    "            self.transform = A.Compose([ToTensorV2()], \n",
    "                                       additional_targets={'label': 'image'})\n",
    "        else:\n",
    "            self.transform = transform            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.item()\n",
    "        data = self.datas[idx]\n",
    "        label = self.labels[idx]\n",
    "        transformed = self.transform(image=data,label=label)\n",
    "        data,label = transformed['image'],transformed['label']\n",
    "        data, label = torch.div(data,255), torch.div(label, 255)\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "b3a2Mp2h-0KJ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images to memory\n",
      "Reading images to memory\n"
     ]
    }
   ],
   "source": [
    "transforms = A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                        A.augmentations.geometric.rotate.RandomRotate90(p=0.5),\n",
    "                      ToTensorV2()\n",
    "                      ],\n",
    "                     additional_targets={'label':'image'})\n",
    "\n",
    "train_data = dataset(train_X, train_Y, transform = transforms)\n",
    "val_data = dataset(train_X, train_Y, transform = None)\n",
    "\n",
    "\n",
    "num_train = len(train_data)\n",
    "valid_percent = 0.2\n",
    "valid_size = round(valid_percent * num_train)\n",
    "train_size = num_train - valid_size\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[:train_size], indices[train_size:]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(val_data, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "val = round(len(train_data)*0.2)\n",
    "tr = len(train_data) - val\n",
    "print(val, tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5VLmSWBn-0KL"
   },
   "outputs": [],
   "source": [
    "class ConvReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_relu = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_relu(x)\n",
    "    \n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class ChannelAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, factor):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.ca = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels//factor, kernel_size=1),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(channels//factor, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.avg_pool2d(x, kernel_size=x.size(dim=-1))\n",
    "        return self.ca(x)\n",
    "    \n",
    "class RCAB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, factor):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        self.ca = ChannelAttn(out_channels, factor)     \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.ca(x1)\n",
    "        x3 = (x1*x2)\n",
    "        x = x+x3\n",
    "        return x\n",
    "\n",
    "class CasBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.rcab = RCAB(channels, channels, factor=16)\n",
    "        self.conv1 = nn.Conv2d(channels*2, channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(channels*3, channels, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(channels*4, channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rcab1 = self.rcab(x)\n",
    "        conv = self.conv1(torch.cat([rcab1, x], dim=1))\n",
    "        rcab2 = self.rcab(conv)\n",
    "        conv = self.conv2(torch.cat([rcab1, rcab2, x], dim=1))\n",
    "        rcab3 = self.rcab(conv)\n",
    "        conv = self.conv3(torch.cat([rcab1, rcab2, rcab3, x], dim=1))\n",
    "        return conv\n",
    "    \n",
    "class Down(nn.Module): \n",
    "    \n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cas = CasBlock(in_channels)\n",
    "        self.conv = nn.Conv2d(mid_channels, out_channels, kernel_size=1)\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self,x1, *args):\n",
    "        x = self.cas(x1)\n",
    "        xp = x\n",
    "        in_size = x.size(dim=-1)\n",
    "        for arg in args:\n",
    "            if in_size == arg.size(dim=-1):\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            elif in_size < arg.size(dim=-1):\n",
    "                factor = arg.size(dim=-1) // in_size\n",
    "                pool = nn.MaxPool2d(factor)\n",
    "                arg = pool(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            else:\n",
    "                factor = in_size // arg.size(dim=-1)\n",
    "                up = nn.Upsample(scale_factor=factor, mode='bicubic', align_corners=True)\n",
    "                arg = up(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.down(x)\n",
    "        return x, xp\n",
    "        \n",
    "class Up(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cas = CasBlock(in_channels)\n",
    "        self.conv = nn.Conv2d(mid_channels, out_channels, kernel_size=1)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bicubic', align_corners=True)\n",
    "        \n",
    "    def forward(self,x1, *args):\n",
    "        x = self.cas(x1)\n",
    "        xp = x\n",
    "        in_size = x.size(dim=-1)\n",
    "        for arg in args:\n",
    "            if in_size == arg.size(dim=-1):\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            elif in_size < arg.size(dim=-1):\n",
    "                factor = arg.size(dim=-1) // in_size\n",
    "                pool = nn.MaxPool2d(factor)\n",
    "                arg = pool(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            else:\n",
    "                factor = in_size // arg.size(dim=-1)\n",
    "                up = nn.Upsample(scale_factor=factor, mode='bicubic', align_corners=True)\n",
    "                arg = up(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.up(x)\n",
    "        return x, xp\n",
    "    \n",
    "class Vanilla(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.cas = CasBlock(in_channels)\n",
    "        self.conv = nn.Conv2d(mid_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self,x1, *args):\n",
    "        x = self.cas(x1)\n",
    "        in_size = x.size(dim=-1)\n",
    "        for arg in args:\n",
    "            if in_size == arg.size(dim=-1):\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            elif in_size < arg.size(dim=-1):\n",
    "                factor = arg.size(dim=-1) // in_size\n",
    "                pool = nn.MaxPool2d(factor)\n",
    "                arg = pool(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "            else:\n",
    "                factor = in_size // arg.size(dim=-1)\n",
    "                up = nn.Upsample(scale_factor=factor, mode='bicubic', align_corners=True)\n",
    "                arg = up(arg)\n",
    "                x = torch.cat([arg,x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class SingleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inc = ConvReLU(1,64)\n",
    "        self.down1 = Down(64,128,128)\n",
    "        self.down2 = Down(128,256,256)\n",
    "        self.down3 = Down(256,512,512)\n",
    "        self.up1 = Up(512,1024,256)\n",
    "        self.up2 = Up(256,1280,128)\n",
    "        self.up3 = Up(128,1408,64)\n",
    "        self.vanilla = Vanilla(64,1472,64)\n",
    "        self.out = SingleConv(64,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #in\n",
    "        x0 = self.inc(x)\n",
    "        \n",
    "        #down1\n",
    "        x1,xp1 = self.down1(x0,x0)\n",
    "        \n",
    "        #down2\n",
    "        x2,xp2 = self.down2(x1,x0,xp1)\n",
    "        \n",
    "        #down3\n",
    "        x3,xp3 = self.down3(x2,x0,xp1,xp2)\n",
    "        \n",
    "        #up1\n",
    "        x4,xp4 = self.up1(x3,x0,xp1,xp2,xp3)\n",
    "        \n",
    "        #up2\n",
    "        x5,xp5 = self.up2(x4,x0,xp1,xp2,xp3,xp4)\n",
    "        \n",
    "        #up3\n",
    "        x6,xp6 = self.up3(x5,x0,xp1,xp2,xp3,xp4,xp5)\n",
    "                \n",
    "        #vanilla\n",
    "        x7 = self.vanilla(x6,x0,xp1,xp2,xp3,xp4,xp5,xp6)\n",
    "        \n",
    "        #out\n",
    "        out = self.out(x7)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC6CYmcq-0KL",
    "outputId": "c3447a39-a159-4d34-a085-26b457885567",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Computation device: ', device)\n",
    "model = Net().to(device)\n",
    "model.load＿state_dict(torch.load(\"pretrain/best-loss.pt\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(win_size, win_sigma):\n",
    "    m = (win_size - 1.)/2.\n",
    "    win = torch.arange(-m,m+1)\n",
    "    win = np.exp(-(win**2)/(2*win_sigma**2))\n",
    "    win_sum = win.sum()\n",
    "    if win_sum != 0:\n",
    "        win /= win_sum\n",
    "    kernel = torch.outer(win,win)\n",
    "    return kernel\n",
    "\n",
    "def ssim(X, Y, win, K, max_val):\n",
    "    C1 = (K[0] * max_val) ** 2\n",
    "    C2 = (K[1] * max_val) ** 2\n",
    "    win = win.to(X.device, dtype=X.dtype)\n",
    "    \n",
    "    mu_x = F.conv2d(F.pad(X,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0)\n",
    "    mu_y = F.conv2d(F.pad(Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0)\n",
    "    mu_xy = mu_x*mu_y\n",
    "    mu_x2 = mu_x**2\n",
    "    mu_y2 = mu_y**2\n",
    "    \n",
    "    sigma_x2 = (F.conv2d(F.pad(X*X,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_x2)\n",
    "    sigma_y2 = (F.conv2d(F.pad(Y*Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_y2)\n",
    "    sigma_xy = (F.conv2d(F.pad(X*Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_xy)\n",
    "    \n",
    "    cs_map = (2 * sigma_xy + C2) / (sigma_x2 + sigma_y2 + C2)\n",
    "    ssim_map = ((2 * mu_xy + C1) / (mu_x2 + mu_y2 + C1)) * cs_map\n",
    "    \n",
    "    ssim = torch.flatten(ssim_map, 2).mean(-1)\n",
    "    cs = torch.flatten(cs_map, 2).mean(-1)\n",
    "    return ssim, cs\n",
    "\n",
    "def ms_ssim(X,Y, win_size = 11, win_sigma = 0.5, K = (0.01,0.03), max_val = 1, weights = None, batch_average = False):\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [0.0517,0.3295,0.3462,0.2726]\n",
    "    weights = torch.FloatTensor(weights).to(X.device, dtype=X.dtype)\n",
    "\n",
    "    win = gaussian_kernel(win_size, win_sigma)\n",
    "    win = win.repeat([X.shape[1]] + [1] * (len(X.shape) - 1))\n",
    "\n",
    "    levels = weights.shape[0]\n",
    "    mcs = []\n",
    "    for i in range(levels):\n",
    "        ssim_m, cs = ssim(X, Y, win=win, max_val=max_val, K=K)\n",
    "        if i < levels - 1:\n",
    "            mcs.append(torch.relu(cs))\n",
    "            padding = [s % 2 for s in X.shape[2:]]\n",
    "            X = F.avg_pool2d(X, kernel_size=2, padding=padding)\n",
    "            Y = F.avg_pool2d(Y, kernel_size=2, padding=padding)\n",
    "\n",
    "    ssim_m = torch.relu(ssim_m)  \n",
    "    mcs_and_ssim = torch.stack(mcs + [ssim_m], dim=0) \n",
    "    ms_ssim_val = torch.prod(mcs_and_ssim ** weights.view(-1, 1, 1), dim=0)\n",
    "    if batch_average:\n",
    "        return ms_ssim_val.mean()\n",
    "    else:\n",
    "        return ms_ssim_val\n",
    "    \n",
    "def gaussian_l1(X, Y, win_sigma =0.5, win_size = 11, max_val = 1, batch_average = False):\n",
    "    win = gaussian_kernel(win_size, win_sigma)\n",
    "    win = win.repeat([X.shape[1]] + [1]*(len(X.shape)-1))\n",
    "    win = win.to(X.device, dtype=X.dtype)\n",
    "    \n",
    "    l1_map = F.l1_loss(X,Y, reduction='none')\n",
    "    gaussian_l1_map = F.conv2d(l1_map, weight = win, stride = 1, padding = 0)\n",
    "    gaussian_l1 = torch.flatten(gaussian_l1_map,2).mean(-1)\n",
    "    if batch_average:\n",
    "        return (gaussian_l1.mean()/max_val)\n",
    "    else:\n",
    "        return (gaussian_l1/max_val)\n",
    "    \n",
    "class hybrid(nn.Module):\n",
    "    def __init__(self,\n",
    "                 win_size = 11,\n",
    "                 win_sigma = 1.5,\n",
    "                 max_val = 1,\n",
    "                 batch_average = False,\n",
    "                 weights=None,\n",
    "                 K=(0.01, 0.03),\n",
    "                 alpha = 0.84,\n",
    "                 compensation = 100.):\n",
    "        super(hybrid, self).__init__()\n",
    "        self.win_size = win_size\n",
    "        self.win_sigma = win_sigma\n",
    "        self.max_val = max_val\n",
    "        self.batch_average = batch_average\n",
    "        self.weights = weights\n",
    "        self.K = K\n",
    "        self.win = gaussian_kernel(self.win_size, self.win_sigma)\n",
    "        self.alpha = alpha\n",
    "        self.compensation = compensation\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        ms = 1 - ms_ssim(X,Y, win_size = self.win_size, win_sigma = self.win_sigma, K = self.K, max_val = self.max_val, weights = self.weights, batch_average = self.batch_average)\n",
    "        l1 = gaussian_l1(X, Y, win_sigma =self.win_sigma, win_size = self.win_size, max_val = self.max_val, batch_average = self.batch_average)\n",
    "        hybrid = self.alpha*ms + (1-self.alpha)*l1\n",
    "        hybrid = hybrid.mean(0)\n",
    "        hybrid = self.compensation*hybrid\n",
    "        return hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='single/8x/best-loss.pt', trace_func=print):\n",
    "\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSNR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SAD1btbX-0KM"
   },
   "outputs": [],
   "source": [
    "def psnr(label, outputs, max_val=1):\n",
    "    \n",
    "    label = label.cpu().detach().numpy()\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    img_diff = outputs - label\n",
    "    rmse = math.sqrt(np.mean((img_diff) ** 2))\n",
    "    if rmse == 0:\n",
    "        return 100\n",
    "    else:\n",
    "        PSNR = 20 * math.log10(max_val / rmse)\n",
    "        return PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0Bk2-Oq-0KN"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "    for image_data, label in tqdm(dataloader, total=int(len(train_data)/dataloader.batch_size)):\n",
    "        data = image_data.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        batch_psnr =  psnr(label, outputs)\n",
    "        running_psnr += batch_psnr\n",
    "    final_loss = running_loss/len(dataloader)\n",
    "    final_psnr = running_psnr/len(dataloader)\n",
    "    return final_loss, final_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4InhMTY-0KN"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image_data, label  in tqdm(dataloader, total=int(len(val_data)/dataloader.batch_size)):\n",
    "            data = image_data.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, label)\n",
    "            running_loss += loss.item()\n",
    "            batch_psnr = psnr(label, outputs)\n",
    "            running_psnr += batch_psnr\n",
    "    final_loss = running_loss/len(dataloader)\n",
    "    final_psnr = running_psnr/len(dataloader)\n",
    "    return final_loss, final_psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "iterations = 0.8*len(train_data)/batch_size\n",
    "step = int(100000/iterations)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) # no weight decay\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = step, gamma=0.5)\n",
    "criterion = hybrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTvdWEyYNYVV",
    "outputId": "3b979ce0-33ba-429c-c329-7a801a39d53d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss, val_loss = [], []\n",
    "train_psnr, val_psnr = [], []\n",
    "best_psnr = 0\n",
    "early_stopping = EarlyStopping(patience=50, verbose=False)\n",
    "start = time.time()\n",
    "path = 'single/8x/best-model.pt'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_psnr = train(model, train_loader)\n",
    "    scheduler.step()\n",
    "    val_epoch_loss, val_epoch_psnr = validate(model, valid_loader)\n",
    "    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n",
    "    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_psnr.append(train_epoch_psnr)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_psnr.append(val_epoch_psnr)\n",
    "    early_stopping(val_epoch_loss, model)\n",
    "    if val_epoch_psnr > best_psnr:\n",
    "        torch.save(model.state_dict(), path)\n",
    "        best_psnr = val_epoch_psnr\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "end = time.time()\n",
    "print(f\"Finished training in: {((end-start)/60):.3f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "9dnjs7Xw-0KO",
    "outputId": "ef733b37-742f-4072-e289-cf050bbdd718",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('single/8x/loss.png')\n",
    "plt.show()\n",
    "train_ls = pd.DataFrame({'train_loss':train_loss,'val_loss':val_loss},columns={'train_loss','val_loss'})\n",
    "train_ls.to_csv('single/8x/loss.csv')\n",
    "# psnr plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_psnr, color='green', label='train PSNR dB')\n",
    "plt.plot(val_psnr, color='blue', label='validataion PSNR dB')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.legend()\n",
    "plt.savefig('single/8x/psnr.png')\n",
    "plt.show()\n",
    "psnr_tr = pd.DataFrame({'train_psnr':train_psnr,'val_psnr':val_psnr},columns={'train_psnr','val_psnr'})\n",
    "psnr_tr.to_csv('single/8x/psnr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = '8'\n",
    "device = 'cuda'\n",
    "model = Net().to(device)\n",
    "model.load＿state_dict(torch.load(\"single/\"+scale+\"x/best-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(path):\n",
    "    test_X = {}\n",
    "    test_Y = {}\n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/low-res/\"+scale+\"x/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_X[folder] = files\n",
    "        \n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/high-res/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_Y[folder] = files\n",
    "        \n",
    "    return test_X,test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['HRCEST07_1', '20220205_135439_DLSRCEST_C164R1_1_5_26_CWCEST_0.6uT_cor_-1p5', \n",
    "       'HRCEST07_5', 'HRCEST07_3', \n",
    "       '20200909_190127_DLCEST_C48_L1_5xFAD_1_17_6_10_7_11_examp_10_CWCEST_0.6uT_front', \n",
    "       '20220205_135439_DLSRCEST_C164R1_1_5_23_CWCEST_0.6uT_sag_0', \n",
    "       'HRCEST07_4', \n",
    "       '20220117_113031_SeWeon_7_Day26_L1_1_24_8_cestRARE_fullZ_0.8uT', \n",
    "       '20201201_114747_ICH_mouse_20201124_C78M2_day1_1_13_10_CWCEST_0.8uT_9696', \n",
    "       'HRCEST07_2']\n",
    "\n",
    "os.mkdir(f\"single/{scale}x/test\")\n",
    "for i in range(len(ls)):\n",
    "    path = ls[i]\n",
    "    test_X, test_Y = read_test_data(path)\n",
    "    test_data = dataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    os.mkdir(f\"single/{scale}x/test/{path}\")\n",
    "    os.mkdir(f\"single/{scale}x/test/{path}/data\")\n",
    "    model.eval()\n",
    "    count = 1\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch[0]\n",
    "            images = images.to(device)  \n",
    "            outputs = model(images)\n",
    "            outputs = outputs.cpu()\n",
    "            tensor = outputs.squeeze()\n",
    "            tensor = torch.clamp(tensor, min = 0.0, max = 1.0)\n",
    "            tensor = tensor*255\n",
    "            image = np.array(tensor, dtype=np.uint8)\n",
    "            cv2.imwrite(f\"single/{scale}x/test/{path}/data/{count:03d}.tif\", image)\n",
    "            count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls = ['HRCEST07_1', '20220205_135439_DLSRCEST_C164R1_1_5_26_CWCEST_0.6uT_cor_-1p5', \n",
    "       'HRCEST07_5', 'HRCEST07_3', \n",
    "       '20200909_190127_DLCEST_C48_L1_5xFAD_1_17_6_10_7_11_examp_10_CWCEST_0.6uT_front', \n",
    "       '20220205_135439_DLSRCEST_C164R1_1_5_23_CWCEST_0.6uT_sag_0', \n",
    "       'HRCEST07_4', \n",
    "       '20220117_113031_SeWeon_7_Day26_L1_1_24_8_cestRARE_fullZ_0.8uT', \n",
    "       '20201201_114747_ICH_mouse_20201124_C78M2_day1_1_13_10_CWCEST_0.8uT_9696', \n",
    "       'HRCEST07_2']\n",
    "\n",
    "# os.mkdir(f\"python-mat/single/{scale}x\")\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    path = ls[i]\n",
    "    test_X, test_Y = read_test_data(path)\n",
    "    test_data = dataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    count = 1\n",
    "    outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch[0]\n",
    "            images = images.to(device)  \n",
    "            output = model(images)\n",
    "            a = psnr(images, output)\n",
    "            print(type(a))\n",
    "            output = output.cpu()\n",
    "            output = output.squeeze(dim=0)\n",
    "            output = torch.clamp(output, min = 0.0, max = 1.0)\n",
    "            output = np.array(output, dtype=np.single)\n",
    "            if count == 1:\n",
    "                outputs = output\n",
    "            else:\n",
    "                outputs = np.concatenate((outputs, output), axis=0)\n",
    "            count +=1\n",
    "    output_path = f\"python-mat/single/{scale}x/{path}.mat\"\n",
    "    odict = {'img': outputs}\n",
    "    # savemat(output_path, odict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = '8'\n",
    "device = 'cuda'\n",
    "model = Net().to(device)\n",
    "model.load＿state_dict(torch.load(\"single/\"+scale+\"x/best-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(path):\n",
    "    test_X = {}\n",
    "    test_Y = {}\n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/low-res/\"+scale+\"x/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_X[folder] = files\n",
    "        \n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/high-res/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_Y[folder] = files\n",
    "        \n",
    "    return test_X,test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data():\n",
    "    test_X = {}\n",
    "    test_Y = {}\n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/low-res/\"+scale+\"x/*/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_X[folder] = files\n",
    "        \n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/high-res/*/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_Y[folder] = files\n",
    "        \n",
    "    return test_X,test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(win_size, win_sigma):\n",
    "    m = (win_size - 1.)/2.\n",
    "    win = torch.arange(-m,m+1)\n",
    "    win = np.exp(-(win**2)/(2*win_sigma**2))\n",
    "    win_sum = win.sum()\n",
    "    if win_sum != 0:\n",
    "        win /= win_sum\n",
    "    kernel = torch.outer(win,win)\n",
    "    return kernel\n",
    "\n",
    "def ssim(X, Y, win, K, max_val):\n",
    "    C1 = (K[0] * max_val) ** 2\n",
    "    C2 = (K[1] * max_val) ** 2\n",
    "    win = win.to(X.device, dtype=X.dtype)\n",
    "    \n",
    "    mu_x = F.conv2d(F.pad(X,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0)\n",
    "    mu_y = F.conv2d(F.pad(Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0)\n",
    "    mu_xy = mu_x*mu_y\n",
    "    mu_x2 = mu_x**2\n",
    "    mu_y2 = mu_y**2\n",
    "    \n",
    "    sigma_x2 = (F.conv2d(F.pad(X*X,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_x2)\n",
    "    sigma_y2 = (F.conv2d(F.pad(Y*Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_y2)\n",
    "    sigma_xy = (F.conv2d(F.pad(X*Y,(5,5,5,5),'replicate'), weight = win, stride = 1, padding = 0) - mu_xy)\n",
    "    \n",
    "    ssim_map = ((2 * mu_xy + C1)*(2 * sigma_xy + C2)) / ((mu_x2 + mu_y2 + C1)*(sigma_x2 + sigma_y2 + C2))\n",
    "    \n",
    "    ssim = torch.flatten(ssim_map, 2).mean(-1)\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images to memory\n"
     ]
    }
   ],
   "source": [
    "# ls = ['HRCEST07_1', '20220205_135439_DLSRCEST_C164R1_1_5_26_CWCEST_0.6uT_cor_-1p5', \n",
    "#        'HRCEST07_5', 'HRCEST07_3', \n",
    "#        '20200909_190127_DLCEST_C48_L1_5xFAD_1_17_6_10_7_11_examp_10_CWCEST_0.6uT_front', \n",
    "#        '20220205_135439_DLSRCEST_C164R1_1_5_23_CWCEST_0.6uT_sag_0', \n",
    "#        'HRCEST07_4', \n",
    "#        '20220117_113031_SeWeon_7_Day26_L1_1_24_8_cestRARE_fullZ_0.8uT', \n",
    "#        '20201201_114747_ICH_mouse_20201124_C78M2_day1_1_13_10_CWCEST_0.8uT_9696', \n",
    "#        'HRCEST07_2']\n",
    "ls = [1]\n",
    "os.mkdir(f\"new-results/{scale}x\")\n",
    "for i in range(len(ls)):\n",
    "    # path = ls[i]\n",
    "    test_X, test_Y = read_test_data()\n",
    "    test_data = dataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    psnr_list = []\n",
    "    low_psnr_list = []\n",
    "    low_ssim_list = []\n",
    "    ssim_list = []\n",
    "    win = gaussian_kernel(11,1.5)\n",
    "    count = 1\n",
    "    with torch.no_grad():\n",
    "        for image_data, label  in test_loader:\n",
    "            win = win.repeat([label.shape[1]] + [1] * (len(label.shape) - 1))\n",
    "            data = image_data.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(data)\n",
    "            low_psnr = psnr(data, label)\n",
    "            low_psnr_list.append(low_psnr)\n",
    "            single_psnr = psnr(outputs, label)\n",
    "            psnr_list.append(single_psnr)\n",
    "            low_ssim = torch.Tensor.cpu(ssim(data,label,win, (0.01,0.03),1))\n",
    "            low_ssim_list.append(low_ssim)\n",
    "            single_ssim = torch.Tensor.cpu(ssim(outputs,label,win, (0.01,0.03),1))\n",
    "            ssim_list.append(single_ssim)\n",
    "        psnr_tr = pd.DataFrame({'low_psnr':low_psnr_list,'single_psnr':psnr_list, 'low_ssim':low_ssim_list, 'single_ssim':ssim_list},columns={'low_psnr','single_psnr','low_ssim','single_ssim'})\n",
    "        psnr_tr.to_csv(f\"new-results/{scale}x/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "running_psnr = 0.0\n",
    "running_psnr_list = []\n",
    "low_running_psnr = 0.0\n",
    "low_running_psnr_list = []\n",
    "low_ssim = 0.0\n",
    "low_ssim_list = []\n",
    "running_ssim = 0.0\n",
    "running_ssim_list = []\n",
    "win = gaussian_kernel(11,1.5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_data, label  in test_loader:\n",
    "        win = win.repeat([label.shape[1]] + [1] * (len(label.shape) - 1))\n",
    "        data = image_data.to(device)\n",
    "        label = label.to(device)\n",
    "        outputs = model(data)\n",
    "        low_batch_psnr = psnr(data, label)\n",
    "        low_running_psnr_list.append(low_batch_psnr)\n",
    "        low_running_psnr += low_batch_psnr\n",
    "        low_batch_ssim = torch.Tensor.cpu(ssim(data,label,win, (0.01,0.03),1))\n",
    "        low_ssim_list.append(low_batch_ssim)\n",
    "        low_ssim += low_batch_ssim.mean()\n",
    "        batch_psnr = psnr(label, outputs)\n",
    "        running_psnr_list.append(batch_psnr)\n",
    "        running_psnr += batch_psnr\n",
    "        batch_ssim = torch.Tensor.cpu(ssim(outputs,label,win, (0.01,0.03),1))\n",
    "        running_ssim_list.append(batch_ssim)\n",
    "        running_ssim += batch_ssim.mean()\n",
    "        outputs = outputs.cpu()\n",
    "final_ssim = running_ssim/len(test_loader)\n",
    "final_low_ssim = low_ssim/len(test_loader)\n",
    "final_low_psnr = low_running_psnr/len(test_loader)\n",
    "final_psnr = running_psnr/len(test_loader)\n",
    "\n",
    "print(\"Validation Low-res-PSNR: \", final_low_psnr)\n",
    "print(\"Validation Low-Res SSIM: \", final_low_ssim)\n",
    "print(\"Validation PSNR: \", final_psnr)\n",
    "print(\"Validation SSIM: \", final_ssim)\n",
    "\n",
    "# psnr_tr = pd.DataFrame({'low_psnr':low_running_psnr_list,'single_psnr':running_psnr_list, 'low_ssim':low_ssim_list, 'single_ssim':running_ssim_list},columns={'low_psnr','single_psnr','low_ssim','single_ssim'})\n",
    "# psnr_tr.to_csv('outputs/rcab-gca/pretrain-model-single/3x/psnr_ssim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing high-res and low-res as matfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = '8'\n",
    "\n",
    "def read_test_data(path):\n",
    "    test_X = {}\n",
    "    test_Y = {}\n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/low-res/\"+scale+\"x/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_X[folder] = files\n",
    "        \n",
    "    folders = glob(\"/home/mri/Documents/dlsr/dataset/test/high-res/\"+path+\"/data\")\n",
    "    for folder in folders:\n",
    "        files = sorted(os.listdir(folder))\n",
    "        test_Y[folder] = files\n",
    "        \n",
    "    return test_X,test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['HRCEST07_1', '20220205_135439_DLSRCEST_C164R1_1_5_26_CWCEST_0.6uT_cor_-1p5', \n",
    "       'HRCEST07_5', 'HRCEST07_3', \n",
    "       '20200909_190127_DLCEST_C48_L1_5xFAD_1_17_6_10_7_11_examp_10_CWCEST_0.6uT_front', \n",
    "       '20220205_135439_DLSRCEST_C164R1_1_5_23_CWCEST_0.6uT_sag_0', \n",
    "       'HRCEST07_4', \n",
    "       '20220117_113031_SeWeon_7_Day26_L1_1_24_8_cestRARE_fullZ_0.8uT', \n",
    "       '20201201_114747_ICH_mouse_20201124_C78M2_day1_1_13_10_CWCEST_0.8uT_9696', \n",
    "       'HRCEST07_2']\n",
    "\n",
    "# os.mkdir(f\"python-mat/low-res/{scale}x\")\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    path = ls[i]\n",
    "    test_X, test_Y = read_test_data(path)\n",
    "    test_data = dataset(test_X, test_Y)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "    count = 1\n",
    "    images= []\n",
    "    labels = []\n",
    "    for image_data, label  in test_loader:\n",
    "        image = image_data.squeeze(dim = 0)\n",
    "        print(image.type())\n",
    "        label = label.squeeze(dim = 0)\n",
    "        image = np.array(image)\n",
    "        label = np.array(label)\n",
    "        if count == 1:\n",
    "            labels = label\n",
    "            images = image\n",
    "        else:\n",
    "            labels = np.concatenate((labels, label), axis=0)\n",
    "            images = np.concatenate((images, image), axis=0)\n",
    "        count +=1\n",
    "    # high_path = f\"python-mat/high-res/{path}.mat\"\n",
    "    # low_path = f\"python-mat/low-res/{scale}x/{path}.mat\"\n",
    "    # hdict = {'img': labels}\n",
    "    # ldict = {'img': images}\n",
    "    # # savemat(high_path, hdict)\n",
    "    # savemat(low_path, ldict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    macs, params = get_model_complexity_info(Net, (1, 96, 96), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True, ignore_modules=[torch.nn.AvgPool2d])\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "act = activation['down3'].squeeze()\n",
    "print(act.size())\n",
    "print((act[k].size()))\n",
    "fig,axarr = plt.subplots(act.size(0)//4,4,figsize=(15,160))\n",
    "for i in range(act.size(0)//4):\n",
    "    for j in range(4):\n",
    "        axarr[i,j].imshow(act[k].detach().cpu().numpy())\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, inp, out):\n",
    "        activation[name] = out.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.down3.register_forward_hook(get_activation('down3'))\n",
    "data = None\n",
    "for img, lbl,edge in test_loader:\n",
    "    data = img.to(device)\n",
    "output = model(data)\n",
    "print(data.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = UNet().to(device)\n",
    "model.load＿state_dict(torch.load(\"abstract/outputs/single-unet-np/best-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.inc = ConvReLU(1,64)\n",
    "#         self.cas = CasBlock(64)\n",
    "#         self.down1 = Down(64,128)\n",
    "#         self.down2 = Down(128,256)\n",
    "#         self.up1 = Up(256,128)\n",
    "#         self.up2 = Up(128,64)\n",
    "#         self.conv = SingleConv(64,64)\n",
    "#         self.out = SingleConv(64,1)\n",
    "        \n",
    "#         self.down1px0      = DownProjection(64,64,2)\n",
    "#         self.down2px0      = DownProjection(64,128,4)\n",
    "#         self.up1px0        = DownProjection(64,256,2)\n",
    "#         self.up2px0        = DownProjection(64,128,1)\n",
    "        \n",
    "#         self.down2px1 = DownProjection(64,128,4)\n",
    "#         self.up1px1   = DownProjection(64,256,2)\n",
    "#         self.up2px1   = DownProjection(64,128,1)\n",
    "        \n",
    "#         self.up1px2   = DownProjection(128,256,1)\n",
    "#         self.up2px2   = UpProjection(128,128,2)\n",
    "#         self.singleconvpx2 = UpProjection(128,64,2) \n",
    "        \n",
    "#         self.up2px3   = UpProjection(256,128,4)\n",
    "#         self.singleconvpx3 = UpProjection(256,64,4)\n",
    "        \n",
    "#         self.singleconvpx4 = UpProjection(128,64,2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         #in\n",
    "#         x0 = self.inc(x)\n",
    "        \n",
    "#         #casblock\n",
    "#         x1 = self.cas(x0)\n",
    "        \n",
    "#         #down1\n",
    "#         xp1 = self.down1px0(x0)\n",
    "#         x2 = self.down1(x1, xp1)\n",
    "        \n",
    "#         #down2\n",
    "#         x0p = self.down2px0(x0)\n",
    "#         x1p = self.down2px1(x1)\n",
    "#         xp2 = x0p+x1p\n",
    "#         x3 = self.down2(x2,xp2)\n",
    "        \n",
    "#         #up1\n",
    "#         x0p = self.up1px0(x0)\n",
    "#         x1p = self.up1px1(x1)\n",
    "#         x2p = self.up1px2(x2)\n",
    "#         xp3 = x0p+x1p+x2p\n",
    "#         x4 = self.up1(x3,xp3)\n",
    "        \n",
    "#         #up2\n",
    "#         x0p = self.up2px0(x0) \n",
    "#         x1p = self.up2px1(x1)\n",
    "#         x2p = self.up2px2(x2)\n",
    "#         x3p = self.up2px3(x3)\n",
    "#         xp4 = x0p+x1p+x2p+x3p\n",
    "#         x5 = self.up2(x4, xp4)\n",
    "        \n",
    "#         #singleconv\n",
    "#         x0p = x0\n",
    "#         x1p = x1\n",
    "#         x2p = self.singleconvpx2(x2)\n",
    "#         x3p = self.singleconvpx3(x3)\n",
    "#         x4p = self.singleconvpx4(x4)\n",
    "#         x6 = x0p+x1p+x2p+x3p+x4p+x5\n",
    "#         x6 = self.conv(x6)\n",
    "        \n",
    "#         #out\n",
    "#         out = self.out(x6)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Down(nn.Module):\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "       \n",
    "#         super().__init__()\n",
    "#         self.downsample = nn.MaxPool2d(2)\n",
    "#         self.casblock = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "#             CasBlock(out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, xp):\n",
    "#         x = self.downsample(x)\n",
    "#         return self.casblock(x+xp)\n",
    "\n",
    "# class Up(nn.Module):\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.up = nn.Upsample(scale_factor=2, mode='bicubic', align_corners=True)\n",
    "#         self.casblock = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "#             CasBlock(out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, xp):\n",
    "#         x = self.up(x)\n",
    "#         return self.casblock(x+xp)\n",
    "    \n",
    "# class DownProjection(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, scale):\n",
    "#         super().__init__()\n",
    "#         self.downproject = nn.Sequential(\n",
    "#             nn.MaxPool2d(scale),\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.downproject(x)\n",
    "\n",
    "# class UpProjection(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, scale):\n",
    "#         super().__init__()\n",
    "#         self.upproject = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor=scale, mode='bicubic', align_corners=True),\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.upproject(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SRCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
